{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 1: Dokumentvektorer\n",
    "I denne oppgaven skal vi se på hvordan vi kan representere dokumenter som vektorer som kan brukes for visualisering og klassifisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korpus, tokens og vokabular  \n",
    "Et *korpus* er en samling av tekster. F.eks Gutenberg-korpuset.  \n",
    "*Tokens* er ord (eller sub-ord), og tokenisering er en del av preprosesseringen for de aller fleste språkteknologioppgaver.  \n",
    "*Vokabularet* til et datasett eller en modell er antall **unike** tokens.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksempelkode\n",
    "ids = gutenberg.fileids()\n",
    "blake_poems = ids[4]\n",
    "gutenberg.words(blake_poems)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Hent ut titlene på bøkene som er skrevet av Jane Austen og William Shakespeare.   \n",
    "    Bruk gutenberg.fileids() for å hente ut titlene. Disse titlene blir vår samling som vi skal jobbe videre med.  \n",
    "    Hvor mange bøker er det? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bruk gutenberg.words for å hente ut selve tekstene. Observer at tekstene allerede er *tokenisert*.  \n",
    "\n",
    "    Hvor mange tokens er det i hver tekst?  \n",
    "    Hvor mange unike tokens er det i hver tekst?\n",
    "    Hvor stort er vokabularet i samlingen vår?  \n",
    "    Sammenlikn størrelsen på vokabularet med totalt antall tokens. \n",
    "    Hvilke 5 tokens forekommer oftest? \n",
    "https://en.wikipedia.org/wiki/Zipf's_law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words-modellen\n",
    "Bag-of-words (BoW) er en måte å representere dokumenter (=tekster) på.  \n",
    "Vi ser bort ifra strukturen og ordrekkefølge i setninger, og lar et dokument representeres som mengden av ord som finnes i dokumentet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Eksempel: \n",
    "```\n",
    "\"Fisk er en type dyr\"                   {\"Fisk\", \"en\", \"er\", \"dyr\", \"type\"}\n",
    "\"Fisk er godt\"                          {\"Fisk\", \"er\", \"godt\"}\n",
    "\"Hester er dyr\"                         {\"Hester\", \"er\",  \"dyr\"}\n",
    "```\n",
    "Her har vi fire tekster, og mengden av tokens disse består av. \n",
    "\n",
    "For å kunne lage dokumentvektorer, lar vi hver dimensjon/feature i dokumentvektoren svare til ett ord i vokabularet.  \n",
    "\n",
    "Eksempel:\n",
    "```\n",
    "                                'godt', 'type', 'dyr', 'Hester', 'Fisk',   \n",
    "\"Fisk er en type dyr\"             0        1      1       0        1     \n",
    "\"Fisk er godt\"                    1        0      0       0        1     \n",
    "\"Hester er dyr\"                   0        0      1       1        0     \n",
    "```\n",
    "Kalles en dokument-ord matrise (eller document-term matrix )\n",
    "\n",
    "Legg merke til at \"en\" og \"er\" er fjernet fra matrisen.\n",
    "Å fjerne funksjonsord som ikke har så mye mening i seg selv, er et grep for å:  \n",
    "1. minske vokabularet, og dermed vektorrommet, og dermed regnekraften som trengs  \n",
    "2. fjerne støy, da funksjonsord typisk forekommer i alle dokumenter  \n",
    "     \n",
    "Vi kaller ord som skal fjernes for *stoppeord* eller *stop words*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Indekser vokabularet\n",
    "    Lag en indekser over hvert token i vokabularet.\n",
    "    Hvert unike token skal ha en unik indeks, og indeksene skal gå fra 0 til størrelsen av vokabularet.\n",
    "    Hvilken indeks har ordet \"Julius\"? (bør kunne hentes i konstant tid med indexer[\"Julius\"], evt indexer(\"Julius\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lag og visualiser dokumentvektorer\n",
    "    Bruk indekseren og bøkene for å lage dokumentvektorer for hver av bøkene i samlingen vår.  \n",
    "    Du kan lage one-hot vektorer (bare binærtall), og/eller vektorer der tallet i hver dimensjon er antall ganger det ordet forekommer i teksten. (lurt å bruke collections.Counter i så fall)\n",
    "    Visualiser dokumentvektorene.  \n",
    "    Hva ser du?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2f915e7280>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eksempel\n",
    "\n",
    "fisk_docs = [\"fisk er en type dyr\", \"fisker fisker ikke fisk\", \"fisk er godt\", \"jeg fisker med stang\"]\n",
    "hest_docs = [\"hester er dyr\", \"jeg har en dyr hest\", \"hester har fine sko\", \"ponni er en type hest\"]\n",
    "docs = fisk_docs + hest_docs\n",
    "\n",
    "voc = set(\" \".join(docs).split())\n",
    "index = {w: i for i, w in enumerate(voc)}\n",
    "\n",
    "# One-hot enkodede BoW-vektorer\n",
    "vecs = np.zeros((len(docs), len(voc)))\n",
    "for i, doc in enumerate(docs):\n",
    "    s = doc.split()\n",
    "    for w in s:\n",
    "        vecs[i][index[w]] = 1\n",
    "\n",
    "# Visualisering\n",
    "pca = PCA(n_components=2)\n",
    "vecs_2d = pca.fit_transform(vecs)\n",
    "x, y = zip(*vecs_2d)\n",
    "\n",
    "i = len(fisk_docs)\n",
    "\n",
    "plt.scatter(x[:i], y[:i], c=\"blue\", label=\"fisk\")\n",
    "plt.scatter(x[i:], y[i:], c=\"red\", label=\"hest\")\n",
    "plt.title(\"BoW visualisering (flatet med PCA)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bonusoppgave\n",
    "    Eksperimenter med forskjellige måter å representere dokumentvektorene.  \n",
    "    Du kan f.eks:\n",
    "- fjerne stoppeord\n",
    "- fjerne non-word-tokens (som tegnsetting)\n",
    "- la vokabularet ignorere små/store bokstaver\n",
    "- vekte ordene med tf-idf (https://en.wikipedia.org/wiki/Tf%E2%80%93idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "\"[\" in punctuation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 2: Ordvektorer og word embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distributional hypothesis og distributional semantics\n",
    "\n",
    "\"Meaning is use\" (Wittgenstein, 1953)  \n",
    "\"You shall know a word by the company it keeps\"  (Firth, 1957)  \n",
    "\"The meaning of entities, and the meaning of grammatical relations\n",
    "among them, is related to the restriction of combinations of these\n",
    "entities relative to other entities\" (Harris, 1968)  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Distributional_semantics  \n",
    "https://www.uio.no/studier/emner/matnat/ifi/IN2110/v23/foiler/05_ordvektorer_2023.pdf\n",
    "\n",
    "Altså: Betydningen til et ord kan finnes ved å se på ordene det omgås med, *konteksten* til ordet.\n",
    "\n",
    "Eksempel:  \n",
    " \n",
    "    \"Damen drikker en kopp kaffe\"  \n",
    "    \"Jens drikker en kopp te\"  \n",
    "    \"Jens drikker et glass vann\"  \n",
    "    \"Hunden drikker vann\"  \n",
    "\n",
    "Grammatisk \"riktig\", men semantisk feil setning:  \n",
    "\"Jeg drikker en stol\"  \n",
    "\"Stol\" vil (så og si) aldri være objekt til verbet \"drikker\". \n",
    "\n",
    "##  Term-term matriser og ordvektorer\n",
    "Vi kan lage ordvektorer ved hjelp av en term-term matrise. (også kalt *co-occurence matrix* eller *term-context matrix*)  \n",
    "Da teller vi opp hvor mange ganger de forskjellige ordene i vokabularet forekommer sammen, altså er i samme kontekt.    \n",
    "Størrelsen på *kontekstvinduet* er hvor mange ord bakover/forover vi henter ut konteksten.\n",
    "\n",
    "Hvis størrelsen på kontekstvinduet er 2, vil vi få denne term-term-matrisen fra eksemplene over:\n",
    "\n",
    "              'Damen', 'Hunden', 'Jens', 'drikker', 'kopp', 'glass', 'kaffe', 'te', 'vann'  \n",
    "    'Damen'       0        0       0        1          1      0         0       0       0  \n",
    "    'Hunden'      0        0       0        1          0      0         0       1       1   \n",
    "    'Jens'        0        0       0        2          1      1         0       0       0  \n",
    "    'drikker'     1        1       2        0          2      1         1       1       2  \n",
    "    'kopp'        1        0       1        2          0      0         1       1       0       \n",
    "    'glass'       0        0       1        1          0      0         0       0       1      \n",
    "    'kaffe'       0        0       0        1          1      0         0       0       0  \n",
    "    'te'          0        0       0        1          1      0         0       0       0  \n",
    "    'vann'        0        1       1        2          0      1         0       0       0  \n",
    "\n",
    "Hver rad/kolonne her er vektoren for det gjeldende ordet  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lag en term-term matrise for ordene i vår samling.  \n",
    "    Du kan velge å fjerne stoppeord og/eller tegnsetting, husk da at det må fjernes fra setningene *før* du teller kontekstordene. (Husk også å ikke inkludere stoppeordene i vokabularet) Du kan også velge å la vokabularet være case insensitive   \n",
    "    La størrelsen på kontekstvinduet være 3 (på hver side av ordet), men ikke gå utenfor setningsgrenser. (Bruk gutenberg.sents istedenfor words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksempelkode\n",
    "sent = gutenberg.sents(ids[0])[0]\n",
    "\n",
    "sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokensene i konteksten til '[' er 'Emma', 'by' og 'Jane'.  \n",
    "Tokensene i konteksten til 'Jane' er '[', 'Emma', 'by', 'Austen', '1816' og ']'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finn likeste ord\n",
    "Nå har vi vektorer som representerer betydningen til de forskjellige ordene. \n",
    "\n",
    "Hvis vi lar hver feature i ordvektorene svare til en dimensjon i et høydimensjonalt rom, kan vi måle avstanden mellom to vektorer med euklidsk avstand (https://en.wikipedia.org/wiki/Euclidean_distance#Higher_dimensions). Vi kan også måle likheten mellom to vektorer med cosinus-likhet (https://en.wikipedia.org/wiki/Cosine_similarity). \n",
    "\n",
    "For å regne ut disse er det lurt å *normalisere* vektorene, det vil si å gjøre dem til enhetsvektorer ved å dele verdien i hver dimensjon på lengden av vektoren (https://mathworld.wolfram.com/NormalizedVector.html)  \n",
    "Gitt at vektorene er normalisert, kan man regne ut cosinus-likheten mellom to vektorer med prikkprodukt. \n",
    "\n",
    "    Lag en funksjon som regner ut avstanden eller likheten mellom to vektorer.\n",
    "\n",
    "    Bruk ordvektorene og vektorrommet til å finne de 10 likeste* ordene til følgende ord:\n",
    "- Emma\n",
    "- George\n",
    "- lovely\n",
    "- King"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Hva ser du?\n",
    "\n",
    "*Husk at hvis du bruker euklidsk avstand, så betyr lavere tall likere ord (avstanden mellom en vektor og seg selv er 0), og hvis du bruker cosinus-likhet så betyr høyere tall likere ord (cosinus-likheten mellom en vektor og seg selv er 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Finn noen vanlige ord som ikke er i vokabularet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bonusoppgave\n",
    "    Lag separate ordvektorer basert på Austen sine bøker og Shakespeare sine bøker.   \n",
    "    (Altså, lag én term-term matrise for Austen-bøkene og én for Shakespeare-bøkene)    \n",
    "    Finn noen ord som forekommer i begge vokabularene, og se om det er store forskjeller på de 10 likeste ordene fra hvert sett av bøker.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "Ordvektorene vi har laget nå er veldig *sparse*: for et gitt ord vil mesteparten av tallene i vektoren være 0.  \n",
    "Vi så også at det er vanlige ord som vi ikke har vektorer for, og at vektorlengden vil øke linjært med vokabularet.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I steden for å lage ordvektorer basert på telling av forekomster, kan man trene nevrale nettverk på ord og kontekst, og så bruke vektene til nettverket som representasjoner for ordene. Da kan vi bestemme dimensjonene til ordvektorene, siden det samsvarer med antall noder i nettverket, og vi får *dense* vektorer (korte med få 0-er). Vi kaller disse ordvektorene for word embeddings.\n",
    "\n",
    "Noen enkle eksempler på algoritmer for å lage word embeddings er å trene nettverk på å predikere et ord gitt sin egen kontekst (Continuous-Bag-of-Words), eller til å predikere kontekten gitt et ord (Skip-Gram).  \n",
    "\n",
    "Siden mer data > bedre resultater, vil man typisk vil man bruke word embeddings som noen andre har trent på enorme corpora. \n",
    "\n",
    "Les mer:  \n",
    "Cbow og skip-gram: (Google, 2013: https://arxiv.org/abs/1301.3781)  \n",
    "GloVe: (Stanford, 2014: https://nlp.stanford.edu/projects/glove/)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Finn de 10 likeste ordene til emma, george, lovely og king ved hjelp av Stanford sine GloVe-vektorer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "glove_model = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model.most_similar(\"sheep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finn de 10 likeste ordene til \"bow\"\n",
    "    Hva ser du? \n",
    "    Hvordan forklarer du dette?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bonus\n",
    "    Tren et lite nettverk på å produsere neste ord gitt de x forrige med disse vektorene og bøkene i samlingen vår.  \n",
    "    Du kan legge til spesielle start- og slutt-tokens på begge ender av hver setning (<sos> og <eos> feks)  \n",
    "    Nå kan du bruke dette nettverket til å generere tekst (start genereringen med start-token, og slutt å generere når modellen predikerer slutt-token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode her"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 3: Contextualized embeddings, tranformers og LLMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualized embeddings\n",
    "Siden (det som ser ut som) samme ord, kan ha forskjellige betydninger, fant man på *contextualized embeddings*.  \n",
    "Da vil ordet \"bow\" i setningene \"Legolas picked up his bow\" og \"The waiter wore a black bow\" representeres av forskjellige vektorer.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konseptet med contextualized embeddings ble introdusert med Paragraph Vector/Doc2Vec, en arkitektur for dokument-embeddings (2014, Stanford: https://arxiv.org/abs/1405.4053)\n",
    "\n",
    "En kjent modell for contextualized embeddings er ELMo (Embeddings from Language Models). Den ble publisert i 2018 (paper: https://arxiv.org/abs/1802.05365) og er basert på BiDirectional LSTMs*) \n",
    "\n",
    "*LSTM = Long Short Term Memory, en type Recurrent Neural Network (RNN) som kan \"huske\" relativt lang kontekst (spesialdesinget for å være bedre enn vanilla RNN på vanishing gradients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualiser ELMo embeddings\n",
    "I denne oppgaven skal vi bruke ELMo for å se hvordan vektorrepresentasjonen til et flertydig ord ser ut i forskjellige kontekster.  \n",
    "\n",
    "    Finn alle setningene i samlingen vår hvor ordet \"bow\" forekommer. \n",
    "    Bruk ELMo til å hente ut word embeddingen for \"bow\" i hver kontekst, og plott disse med ditt favorittverktøy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\").signatures[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fyll inn kode her:\n",
    "# TODO: \n",
    "# Finn setninger - (bruk de tokeniserte setningene vi fikk fra gutenberg.sents)\n",
    "# Pad setningene med \"\" på slutten slik at alle listene med ord er like lange\n",
    "# Spar på lengdene på de originale setningene (altså antall tokens uten padding), sånn at paddingen ikke blir en del av vektorene\n",
    "\n",
    "# padded_sents = de paddede sentingene, input_lens er lengden av de faktiske setningene \n",
    "embeddings_tensors = elmo(tokens=tf.constant(padded_sents), sequence_len=tf.constant(input_lens))\n",
    "indices = [sent.index(\"bow\") for sent in sents]\n",
    "embs = [emb[i] for i, emb in zip(indices, embeddings_tensors[\"elmo\"])]\n",
    "\n",
    "# TODO: Visualiser embeddingsene i et scatterplot "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer-arkitekturen og Large Language Models (LLMs) (to be continued)\n",
    "En annen kjent modell for contextualized word embeddings er BERT (2018, paper: https://arxiv.org/abs/1810.04805).  \n",
    "Basert på encoder-delen av transformer-arkitekturen*, lager BERT contextualized word embeddings.  \n",
    "BERT er trent på bl.a masked language modelling, og kan brukes til å klassifisere sekvenser (ordklasser, dependensgrafer, entitetsekstrahering). \n",
    "\n",
    "*Transformers-arkitekturen ble presentert i det nå legendariske paperet Attention is all you need (2017, https://arxiv.org/abs/1706.03762)  \n",
    "Mye mer kontekst kan \"huskes\" (det går kanter mellom hvert par av tokens) og den er ikke sekvensiell på samme måte som LSTMer som betyr at det er lett å parallelisere trening og inference  \n",
    "\n",
    "GPT-modellene er også basert på transformers. Og T5 (https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) (så og si all nyere språkteknologi)\n",
    "\n",
    "Jeg rakkk ikke mer, vi får ta resten senere!!!   \n",
    "Dypere om transformers og multimodale modeller kommer neste gang kan vi si\n",
    "\n",
    "Anbefaler Andrey sin talk her:  \n",
    "https://www.youtube.com/watch?v=mtM6D2ySME8  \n",
    "slides: https://www.nora.ai/cuttingedgeai/cuttinedge-ai-february/presentations/06---andrey-kutuzov---lm_chatgpt.pdf  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 13 2023, 10:26:41) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc47d3908329ff540dbbbacaf6c5a69db37d2b1db7c0ce14879479d2f9f8507d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
